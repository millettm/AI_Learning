{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.4536082474226806,
  "eval_steps": 500,
  "global_step": 120,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.020618556701030927,
      "grad_norm": 21.5922794342041,
      "learning_rate": 0.0,
      "loss": 17.1898,
      "step": 1
    },
    {
      "epoch": 0.041237113402061855,
      "grad_norm": 19.387638092041016,
      "learning_rate": 5e-05,
      "loss": 17.3364,
      "step": 2
    },
    {
      "epoch": 0.061855670103092786,
      "grad_norm": 21.481809616088867,
      "learning_rate": 4.9657534246575346e-05,
      "loss": 17.0608,
      "step": 3
    },
    {
      "epoch": 0.08247422680412371,
      "grad_norm": 22.30386734008789,
      "learning_rate": 4.9315068493150684e-05,
      "loss": 16.5872,
      "step": 4
    },
    {
      "epoch": 0.10309278350515463,
      "grad_norm": 22.487586975097656,
      "learning_rate": 4.8972602739726034e-05,
      "loss": 16.3947,
      "step": 5
    },
    {
      "epoch": 0.12371134020618557,
      "grad_norm": 25.722307205200195,
      "learning_rate": 4.863013698630137e-05,
      "loss": 15.8105,
      "step": 6
    },
    {
      "epoch": 0.14432989690721648,
      "grad_norm": 28.542400360107422,
      "learning_rate": 4.8287671232876716e-05,
      "loss": 15.2682,
      "step": 7
    },
    {
      "epoch": 0.16494845360824742,
      "grad_norm": 29.77732276916504,
      "learning_rate": 4.794520547945205e-05,
      "loss": 14.9193,
      "step": 8
    },
    {
      "epoch": 0.18556701030927836,
      "grad_norm": 33.32551956176758,
      "learning_rate": 4.7602739726027403e-05,
      "loss": 14.3228,
      "step": 9
    },
    {
      "epoch": 0.20618556701030927,
      "grad_norm": 37.55258560180664,
      "learning_rate": 4.726027397260274e-05,
      "loss": 13.6558,
      "step": 10
    },
    {
      "epoch": 0.2268041237113402,
      "grad_norm": 39.08740234375,
      "learning_rate": 4.6917808219178085e-05,
      "loss": 13.1666,
      "step": 11
    },
    {
      "epoch": 0.24742268041237114,
      "grad_norm": 45.75041198730469,
      "learning_rate": 4.657534246575342e-05,
      "loss": 12.0574,
      "step": 12
    },
    {
      "epoch": 0.26804123711340205,
      "grad_norm": 48.47603988647461,
      "learning_rate": 4.623287671232877e-05,
      "loss": 11.5825,
      "step": 13
    },
    {
      "epoch": 0.28865979381443296,
      "grad_norm": 49.012001037597656,
      "learning_rate": 4.589041095890411e-05,
      "loss": 10.3258,
      "step": 14
    },
    {
      "epoch": 0.30927835051546393,
      "grad_norm": 54.778411865234375,
      "learning_rate": 4.5547945205479454e-05,
      "loss": 9.6727,
      "step": 15
    },
    {
      "epoch": 0.32989690721649484,
      "grad_norm": 61.660728454589844,
      "learning_rate": 4.520547945205479e-05,
      "loss": 8.0491,
      "step": 16
    },
    {
      "epoch": 0.35051546391752575,
      "grad_norm": 67.43046569824219,
      "learning_rate": 4.486301369863014e-05,
      "loss": 7.0713,
      "step": 17
    },
    {
      "epoch": 0.3711340206185567,
      "grad_norm": 68.63656616210938,
      "learning_rate": 4.452054794520548e-05,
      "loss": 6.0531,
      "step": 18
    },
    {
      "epoch": 0.3917525773195876,
      "grad_norm": 70.52140045166016,
      "learning_rate": 4.417808219178082e-05,
      "loss": 4.4854,
      "step": 19
    },
    {
      "epoch": 0.41237113402061853,
      "grad_norm": 65.55616760253906,
      "learning_rate": 4.383561643835617e-05,
      "loss": 3.4128,
      "step": 20
    },
    {
      "epoch": 0.4329896907216495,
      "grad_norm": 46.678749084472656,
      "learning_rate": 4.349315068493151e-05,
      "loss": 1.6794,
      "step": 21
    },
    {
      "epoch": 0.4536082474226804,
      "grad_norm": 28.822498321533203,
      "learning_rate": 4.3150684931506855e-05,
      "loss": 1.0382,
      "step": 22
    },
    {
      "epoch": 0.4742268041237113,
      "grad_norm": 26.917720794677734,
      "learning_rate": 4.280821917808219e-05,
      "loss": 1.0155,
      "step": 23
    },
    {
      "epoch": 0.4948453608247423,
      "grad_norm": 10.786391258239746,
      "learning_rate": 4.2465753424657536e-05,
      "loss": 0.5632,
      "step": 24
    },
    {
      "epoch": 0.5154639175257731,
      "grad_norm": 3.7782979011535645,
      "learning_rate": 4.212328767123288e-05,
      "loss": 0.435,
      "step": 25
    },
    {
      "epoch": 0.5360824742268041,
      "grad_norm": 1.5777652263641357,
      "learning_rate": 4.1780821917808224e-05,
      "loss": 0.3791,
      "step": 26
    },
    {
      "epoch": 0.5567010309278351,
      "grad_norm": 1.2714552879333496,
      "learning_rate": 4.143835616438356e-05,
      "loss": 0.3656,
      "step": 27
    },
    {
      "epoch": 0.5773195876288659,
      "grad_norm": 0.9902676343917847,
      "learning_rate": 4.1095890410958905e-05,
      "loss": 0.3506,
      "step": 28
    },
    {
      "epoch": 0.5979381443298969,
      "grad_norm": 0.8217443227767944,
      "learning_rate": 4.075342465753425e-05,
      "loss": 0.3709,
      "step": 29
    },
    {
      "epoch": 0.6185567010309279,
      "grad_norm": 0.8923215866088867,
      "learning_rate": 4.041095890410959e-05,
      "loss": 0.3408,
      "step": 30
    },
    {
      "epoch": 0.6391752577319587,
      "grad_norm": 0.6736725568771362,
      "learning_rate": 4.006849315068493e-05,
      "loss": 0.3461,
      "step": 31
    },
    {
      "epoch": 0.6597938144329897,
      "grad_norm": 0.4275885820388794,
      "learning_rate": 3.9726027397260274e-05,
      "loss": 0.3548,
      "step": 32
    },
    {
      "epoch": 0.6804123711340206,
      "grad_norm": 0.3304567337036133,
      "learning_rate": 3.938356164383562e-05,
      "loss": 0.4025,
      "step": 33
    },
    {
      "epoch": 0.7010309278350515,
      "grad_norm": 0.2403475046157837,
      "learning_rate": 3.904109589041096e-05,
      "loss": 0.3613,
      "step": 34
    },
    {
      "epoch": 0.7216494845360825,
      "grad_norm": 0.23942090570926666,
      "learning_rate": 3.86986301369863e-05,
      "loss": 0.3602,
      "step": 35
    },
    {
      "epoch": 0.7422680412371134,
      "grad_norm": 0.18404865264892578,
      "learning_rate": 3.8356164383561644e-05,
      "loss": 0.338,
      "step": 36
    },
    {
      "epoch": 0.7628865979381443,
      "grad_norm": 0.17273037135601044,
      "learning_rate": 3.801369863013699e-05,
      "loss": 0.3171,
      "step": 37
    },
    {
      "epoch": 0.7835051546391752,
      "grad_norm": 0.17005254328250885,
      "learning_rate": 3.767123287671233e-05,
      "loss": 0.3466,
      "step": 38
    },
    {
      "epoch": 0.8041237113402062,
      "grad_norm": 0.18212974071502686,
      "learning_rate": 3.7328767123287675e-05,
      "loss": 0.3519,
      "step": 39
    },
    {
      "epoch": 0.8247422680412371,
      "grad_norm": 0.15205325186252594,
      "learning_rate": 3.698630136986301e-05,
      "loss": 0.3356,
      "step": 40
    },
    {
      "epoch": 0.845360824742268,
      "grad_norm": 0.15312770009040833,
      "learning_rate": 3.664383561643836e-05,
      "loss": 0.3302,
      "step": 41
    },
    {
      "epoch": 0.865979381443299,
      "grad_norm": 0.17229187488555908,
      "learning_rate": 3.63013698630137e-05,
      "loss": 0.323,
      "step": 42
    },
    {
      "epoch": 0.8865979381443299,
      "grad_norm": 0.15504257380962372,
      "learning_rate": 3.5958904109589045e-05,
      "loss": 0.3421,
      "step": 43
    },
    {
      "epoch": 0.9072164948453608,
      "grad_norm": 0.15545663237571716,
      "learning_rate": 3.561643835616438e-05,
      "loss": 0.3538,
      "step": 44
    },
    {
      "epoch": 0.9278350515463918,
      "grad_norm": 0.16050104796886444,
      "learning_rate": 3.527397260273973e-05,
      "loss": 0.3589,
      "step": 45
    },
    {
      "epoch": 0.9484536082474226,
      "grad_norm": 0.15735745429992676,
      "learning_rate": 3.493150684931507e-05,
      "loss": 0.3158,
      "step": 46
    },
    {
      "epoch": 0.9690721649484536,
      "grad_norm": 0.14145530760288239,
      "learning_rate": 3.4589041095890414e-05,
      "loss": 0.3433,
      "step": 47
    },
    {
      "epoch": 0.9896907216494846,
      "grad_norm": 0.12668900191783905,
      "learning_rate": 3.424657534246575e-05,
      "loss": 0.3275,
      "step": 48
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.1482524275779724,
      "learning_rate": 3.39041095890411e-05,
      "loss": 0.3007,
      "step": 49
    },
    {
      "epoch": 1.0206185567010309,
      "grad_norm": 0.1310914158821106,
      "learning_rate": 3.356164383561644e-05,
      "loss": 0.316,
      "step": 50
    },
    {
      "epoch": 1.041237113402062,
      "grad_norm": 0.1299949288368225,
      "learning_rate": 3.321917808219178e-05,
      "loss": 0.2991,
      "step": 51
    },
    {
      "epoch": 1.0618556701030928,
      "grad_norm": 0.13389131426811218,
      "learning_rate": 3.287671232876712e-05,
      "loss": 0.34,
      "step": 52
    },
    {
      "epoch": 1.0824742268041236,
      "grad_norm": 0.13560597598552704,
      "learning_rate": 3.253424657534247e-05,
      "loss": 0.3142,
      "step": 53
    },
    {
      "epoch": 1.1030927835051547,
      "grad_norm": 0.1214112862944603,
      "learning_rate": 3.219178082191781e-05,
      "loss": 0.2979,
      "step": 54
    },
    {
      "epoch": 1.1237113402061856,
      "grad_norm": 0.1271042823791504,
      "learning_rate": 3.184931506849315e-05,
      "loss": 0.2643,
      "step": 55
    },
    {
      "epoch": 1.1443298969072164,
      "grad_norm": 0.12576650083065033,
      "learning_rate": 3.1506849315068496e-05,
      "loss": 0.3141,
      "step": 56
    },
    {
      "epoch": 1.1649484536082475,
      "grad_norm": 0.1373579353094101,
      "learning_rate": 3.116438356164384e-05,
      "loss": 0.2717,
      "step": 57
    },
    {
      "epoch": 1.1855670103092784,
      "grad_norm": 0.1338140368461609,
      "learning_rate": 3.082191780821918e-05,
      "loss": 0.3233,
      "step": 58
    },
    {
      "epoch": 1.2061855670103092,
      "grad_norm": 0.1550045758485794,
      "learning_rate": 3.047945205479452e-05,
      "loss": 0.3189,
      "step": 59
    },
    {
      "epoch": 1.2268041237113403,
      "grad_norm": 0.11765288561582565,
      "learning_rate": 3.0136986301369862e-05,
      "loss": 0.3119,
      "step": 60
    },
    {
      "epoch": 1.2474226804123711,
      "grad_norm": 0.13293471932411194,
      "learning_rate": 2.979452054794521e-05,
      "loss": 0.2942,
      "step": 61
    },
    {
      "epoch": 1.268041237113402,
      "grad_norm": 0.11274644732475281,
      "learning_rate": 2.945205479452055e-05,
      "loss": 0.3102,
      "step": 62
    },
    {
      "epoch": 1.2886597938144329,
      "grad_norm": 0.16395410895347595,
      "learning_rate": 2.910958904109589e-05,
      "loss": 0.347,
      "step": 63
    },
    {
      "epoch": 1.309278350515464,
      "grad_norm": 0.1051282212138176,
      "learning_rate": 2.8767123287671234e-05,
      "loss": 0.247,
      "step": 64
    },
    {
      "epoch": 1.3298969072164948,
      "grad_norm": 0.11699643731117249,
      "learning_rate": 2.842465753424658e-05,
      "loss": 0.3159,
      "step": 65
    },
    {
      "epoch": 1.3505154639175259,
      "grad_norm": 0.16335225105285645,
      "learning_rate": 2.808219178082192e-05,
      "loss": 0.3084,
      "step": 66
    },
    {
      "epoch": 1.3711340206185567,
      "grad_norm": 0.12664754688739777,
      "learning_rate": 2.7739726027397263e-05,
      "loss": 0.2764,
      "step": 67
    },
    {
      "epoch": 1.3917525773195876,
      "grad_norm": 0.13104279339313507,
      "learning_rate": 2.7397260273972603e-05,
      "loss": 0.3116,
      "step": 68
    },
    {
      "epoch": 1.4123711340206184,
      "grad_norm": 0.1484416276216507,
      "learning_rate": 2.7054794520547947e-05,
      "loss": 0.3243,
      "step": 69
    },
    {
      "epoch": 1.4329896907216495,
      "grad_norm": 0.1309434324502945,
      "learning_rate": 2.671232876712329e-05,
      "loss": 0.3423,
      "step": 70
    },
    {
      "epoch": 1.4536082474226804,
      "grad_norm": 0.12634898722171783,
      "learning_rate": 2.6369863013698632e-05,
      "loss": 0.2996,
      "step": 71
    },
    {
      "epoch": 1.4742268041237114,
      "grad_norm": 0.12206462770700455,
      "learning_rate": 2.6027397260273973e-05,
      "loss": 0.3098,
      "step": 72
    },
    {
      "epoch": 1.4948453608247423,
      "grad_norm": 0.13168905675411224,
      "learning_rate": 2.568493150684932e-05,
      "loss": 0.3208,
      "step": 73
    },
    {
      "epoch": 1.5154639175257731,
      "grad_norm": 0.12797723710536957,
      "learning_rate": 2.534246575342466e-05,
      "loss": 0.3026,
      "step": 74
    },
    {
      "epoch": 1.536082474226804,
      "grad_norm": 0.13610337674617767,
      "learning_rate": 2.5e-05,
      "loss": 0.329,
      "step": 75
    },
    {
      "epoch": 1.556701030927835,
      "grad_norm": 0.1233840137720108,
      "learning_rate": 2.4657534246575342e-05,
      "loss": 0.2975,
      "step": 76
    },
    {
      "epoch": 1.577319587628866,
      "grad_norm": 0.1606120616197586,
      "learning_rate": 2.4315068493150686e-05,
      "loss": 0.2966,
      "step": 77
    },
    {
      "epoch": 1.597938144329897,
      "grad_norm": 0.1319980025291443,
      "learning_rate": 2.3972602739726026e-05,
      "loss": 0.3113,
      "step": 78
    },
    {
      "epoch": 1.6185567010309279,
      "grad_norm": 0.12141396105289459,
      "learning_rate": 2.363013698630137e-05,
      "loss": 0.2902,
      "step": 79
    },
    {
      "epoch": 1.6391752577319587,
      "grad_norm": 0.1313188374042511,
      "learning_rate": 2.328767123287671e-05,
      "loss": 0.3302,
      "step": 80
    },
    {
      "epoch": 1.6597938144329896,
      "grad_norm": 0.12836016714572906,
      "learning_rate": 2.2945205479452055e-05,
      "loss": 0.3241,
      "step": 81
    },
    {
      "epoch": 1.6804123711340206,
      "grad_norm": 0.12425370514392853,
      "learning_rate": 2.2602739726027396e-05,
      "loss": 0.2996,
      "step": 82
    },
    {
      "epoch": 1.7010309278350515,
      "grad_norm": 0.13048212230205536,
      "learning_rate": 2.226027397260274e-05,
      "loss": 0.2809,
      "step": 83
    },
    {
      "epoch": 1.7216494845360826,
      "grad_norm": 0.14734409749507904,
      "learning_rate": 2.1917808219178083e-05,
      "loss": 0.3243,
      "step": 84
    },
    {
      "epoch": 1.7422680412371134,
      "grad_norm": 0.12644736468791962,
      "learning_rate": 2.1575342465753427e-05,
      "loss": 0.2956,
      "step": 85
    },
    {
      "epoch": 1.7628865979381443,
      "grad_norm": 0.1256205439567566,
      "learning_rate": 2.1232876712328768e-05,
      "loss": 0.3267,
      "step": 86
    },
    {
      "epoch": 1.7835051546391751,
      "grad_norm": 0.1349618136882782,
      "learning_rate": 2.0890410958904112e-05,
      "loss": 0.2917,
      "step": 87
    },
    {
      "epoch": 1.8041237113402062,
      "grad_norm": 0.12650170922279358,
      "learning_rate": 2.0547945205479453e-05,
      "loss": 0.2981,
      "step": 88
    },
    {
      "epoch": 1.824742268041237,
      "grad_norm": 0.1145445853471756,
      "learning_rate": 2.0205479452054797e-05,
      "loss": 0.3122,
      "step": 89
    },
    {
      "epoch": 1.8453608247422681,
      "grad_norm": 0.13224510848522186,
      "learning_rate": 1.9863013698630137e-05,
      "loss": 0.354,
      "step": 90
    },
    {
      "epoch": 1.865979381443299,
      "grad_norm": 0.11443019658327103,
      "learning_rate": 1.952054794520548e-05,
      "loss": 0.2878,
      "step": 91
    },
    {
      "epoch": 1.8865979381443299,
      "grad_norm": 0.14067213237285614,
      "learning_rate": 1.9178082191780822e-05,
      "loss": 0.3197,
      "step": 92
    },
    {
      "epoch": 1.9072164948453607,
      "grad_norm": 0.13698819279670715,
      "learning_rate": 1.8835616438356166e-05,
      "loss": 0.3118,
      "step": 93
    },
    {
      "epoch": 1.9278350515463918,
      "grad_norm": 0.1373106837272644,
      "learning_rate": 1.8493150684931506e-05,
      "loss": 0.3006,
      "step": 94
    },
    {
      "epoch": 1.9484536082474226,
      "grad_norm": 0.1410289704799652,
      "learning_rate": 1.815068493150685e-05,
      "loss": 0.3211,
      "step": 95
    },
    {
      "epoch": 1.9690721649484537,
      "grad_norm": 0.13924214243888855,
      "learning_rate": 1.780821917808219e-05,
      "loss": 0.3099,
      "step": 96
    },
    {
      "epoch": 1.9896907216494846,
      "grad_norm": 0.14198894798755646,
      "learning_rate": 1.7465753424657535e-05,
      "loss": 0.3021,
      "step": 97
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.15182863175868988,
      "learning_rate": 1.7123287671232875e-05,
      "loss": 0.2719,
      "step": 98
    },
    {
      "epoch": 2.020618556701031,
      "grad_norm": 0.13803793489933014,
      "learning_rate": 1.678082191780822e-05,
      "loss": 0.3275,
      "step": 99
    },
    {
      "epoch": 2.0412371134020617,
      "grad_norm": 0.14382372796535492,
      "learning_rate": 1.643835616438356e-05,
      "loss": 0.298,
      "step": 100
    },
    {
      "epoch": 2.0618556701030926,
      "grad_norm": 0.12369076162576675,
      "learning_rate": 1.6095890410958904e-05,
      "loss": 0.2746,
      "step": 101
    },
    {
      "epoch": 2.082474226804124,
      "grad_norm": 0.12915804982185364,
      "learning_rate": 1.5753424657534248e-05,
      "loss": 0.3165,
      "step": 102
    },
    {
      "epoch": 2.1030927835051547,
      "grad_norm": 0.1288401186466217,
      "learning_rate": 1.541095890410959e-05,
      "loss": 0.3209,
      "step": 103
    },
    {
      "epoch": 2.1237113402061856,
      "grad_norm": 0.12768681347370148,
      "learning_rate": 1.5068493150684931e-05,
      "loss": 0.2932,
      "step": 104
    },
    {
      "epoch": 2.1443298969072164,
      "grad_norm": 0.11962056159973145,
      "learning_rate": 1.4726027397260275e-05,
      "loss": 0.2531,
      "step": 105
    },
    {
      "epoch": 2.1649484536082473,
      "grad_norm": 0.14119477570056915,
      "learning_rate": 1.4383561643835617e-05,
      "loss": 0.3044,
      "step": 106
    },
    {
      "epoch": 2.1855670103092786,
      "grad_norm": 0.11843520402908325,
      "learning_rate": 1.404109589041096e-05,
      "loss": 0.2998,
      "step": 107
    },
    {
      "epoch": 2.2061855670103094,
      "grad_norm": 0.14971759915351868,
      "learning_rate": 1.3698630136986302e-05,
      "loss": 0.3211,
      "step": 108
    },
    {
      "epoch": 2.2268041237113403,
      "grad_norm": 0.12301171571016312,
      "learning_rate": 1.3356164383561646e-05,
      "loss": 0.2709,
      "step": 109
    },
    {
      "epoch": 2.247422680412371,
      "grad_norm": 0.1270776242017746,
      "learning_rate": 1.3013698630136986e-05,
      "loss": 0.2736,
      "step": 110
    },
    {
      "epoch": 2.268041237113402,
      "grad_norm": 0.18392737209796906,
      "learning_rate": 1.267123287671233e-05,
      "loss": 0.3064,
      "step": 111
    },
    {
      "epoch": 2.288659793814433,
      "grad_norm": 0.12458404898643494,
      "learning_rate": 1.2328767123287671e-05,
      "loss": 0.272,
      "step": 112
    },
    {
      "epoch": 2.3092783505154637,
      "grad_norm": 0.12881599366664886,
      "learning_rate": 1.1986301369863013e-05,
      "loss": 0.2774,
      "step": 113
    },
    {
      "epoch": 2.329896907216495,
      "grad_norm": 0.1340297907590866,
      "learning_rate": 1.1643835616438355e-05,
      "loss": 0.296,
      "step": 114
    },
    {
      "epoch": 2.350515463917526,
      "grad_norm": 0.14889086782932281,
      "learning_rate": 1.1301369863013698e-05,
      "loss": 0.2888,
      "step": 115
    },
    {
      "epoch": 2.3711340206185567,
      "grad_norm": 0.1240309551358223,
      "learning_rate": 1.0958904109589042e-05,
      "loss": 0.2877,
      "step": 116
    },
    {
      "epoch": 2.3917525773195876,
      "grad_norm": 0.1766854226589203,
      "learning_rate": 1.0616438356164384e-05,
      "loss": 0.328,
      "step": 117
    },
    {
      "epoch": 2.4123711340206184,
      "grad_norm": 0.1410667449235916,
      "learning_rate": 1.0273972602739726e-05,
      "loss": 0.3281,
      "step": 118
    },
    {
      "epoch": 2.4329896907216497,
      "grad_norm": 0.12304968386888504,
      "learning_rate": 9.931506849315069e-06,
      "loss": 0.2866,
      "step": 119
    },
    {
      "epoch": 2.4536082474226806,
      "grad_norm": 0.16330167651176453,
      "learning_rate": 9.589041095890411e-06,
      "loss": 0.3012,
      "step": 120
    }
  ],
  "logging_steps": 1,
  "max_steps": 147,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 10,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4125129487417344.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
