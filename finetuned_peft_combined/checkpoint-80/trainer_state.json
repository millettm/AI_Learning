{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.02866869736606343,
  "eval_steps": 500,
  "global_step": 80,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00035835871707579287,
      "grad_norm": 20.3043155670166,
      "learning_rate": 0.0,
      "loss": 15.7337,
      "step": 1
    },
    {
      "epoch": 0.0007167174341515857,
      "grad_norm": 18.318492889404297,
      "learning_rate": 5e-05,
      "loss": 15.8805,
      "step": 2
    },
    {
      "epoch": 0.0010750761512273786,
      "grad_norm": 18.94686508178711,
      "learning_rate": 4.999402771141902e-05,
      "loss": 15.5972,
      "step": 3
    },
    {
      "epoch": 0.0014334348683031715,
      "grad_norm": 20.0352840423584,
      "learning_rate": 4.9988055422838034e-05,
      "loss": 15.2382,
      "step": 4
    },
    {
      "epoch": 0.0017917935853789643,
      "grad_norm": 20.746166229248047,
      "learning_rate": 4.998208313425705e-05,
      "loss": 14.7711,
      "step": 5
    },
    {
      "epoch": 0.002150152302454757,
      "grad_norm": 24.307992935180664,
      "learning_rate": 4.9976110845676066e-05,
      "loss": 14.3096,
      "step": 6
    },
    {
      "epoch": 0.00250851101953055,
      "grad_norm": 25.649250030517578,
      "learning_rate": 4.997013855709508e-05,
      "loss": 14.0469,
      "step": 7
    },
    {
      "epoch": 0.002866869736606343,
      "grad_norm": 29.355260848999023,
      "learning_rate": 4.99641662685141e-05,
      "loss": 13.1152,
      "step": 8
    },
    {
      "epoch": 0.003225228453682136,
      "grad_norm": 28.649314880371094,
      "learning_rate": 4.995819397993311e-05,
      "loss": 12.9541,
      "step": 9
    },
    {
      "epoch": 0.0035835871707579287,
      "grad_norm": 33.65465545654297,
      "learning_rate": 4.995222169135213e-05,
      "loss": 12.207,
      "step": 10
    },
    {
      "epoch": 0.003941945887833721,
      "grad_norm": 35.941829681396484,
      "learning_rate": 4.9946249402771146e-05,
      "loss": 11.6176,
      "step": 11
    },
    {
      "epoch": 0.004300304604909514,
      "grad_norm": 40.75389862060547,
      "learning_rate": 4.994027711419016e-05,
      "loss": 10.6479,
      "step": 12
    },
    {
      "epoch": 0.004658663321985307,
      "grad_norm": 44.15620803833008,
      "learning_rate": 4.993430482560917e-05,
      "loss": 9.8768,
      "step": 13
    },
    {
      "epoch": 0.0050170220390611,
      "grad_norm": 44.37617492675781,
      "learning_rate": 4.9928332537028194e-05,
      "loss": 9.2517,
      "step": 14
    },
    {
      "epoch": 0.005375380756136893,
      "grad_norm": 46.66408157348633,
      "learning_rate": 4.992236024844721e-05,
      "loss": 8.0375,
      "step": 15
    },
    {
      "epoch": 0.005733739473212686,
      "grad_norm": 50.66767501831055,
      "learning_rate": 4.9916387959866226e-05,
      "loss": 6.8855,
      "step": 16
    },
    {
      "epoch": 0.006092098190288478,
      "grad_norm": 55.534969329833984,
      "learning_rate": 4.9910415671285235e-05,
      "loss": 5.8985,
      "step": 17
    },
    {
      "epoch": 0.006450456907364272,
      "grad_norm": 57.557167053222656,
      "learning_rate": 4.990444338270425e-05,
      "loss": 4.6042,
      "step": 18
    },
    {
      "epoch": 0.006808815624440064,
      "grad_norm": 55.75872039794922,
      "learning_rate": 4.9898471094123274e-05,
      "loss": 3.8512,
      "step": 19
    },
    {
      "epoch": 0.007167174341515857,
      "grad_norm": 49.14149856567383,
      "learning_rate": 4.989249880554229e-05,
      "loss": 2.5176,
      "step": 20
    },
    {
      "epoch": 0.00752553305859165,
      "grad_norm": 30.030378341674805,
      "learning_rate": 4.98865265169613e-05,
      "loss": 1.3699,
      "step": 21
    },
    {
      "epoch": 0.007883891775667442,
      "grad_norm": 19.32173728942871,
      "learning_rate": 4.9880554228380315e-05,
      "loss": 1.1864,
      "step": 22
    },
    {
      "epoch": 0.008242250492743236,
      "grad_norm": 6.639308452606201,
      "learning_rate": 4.987458193979933e-05,
      "loss": 0.7265,
      "step": 23
    },
    {
      "epoch": 0.008600609209819029,
      "grad_norm": 5.71967887878418,
      "learning_rate": 4.9868609651218354e-05,
      "loss": 0.6254,
      "step": 24
    },
    {
      "epoch": 0.008958967926894821,
      "grad_norm": 2.0705337524414062,
      "learning_rate": 4.9862637362637363e-05,
      "loss": 0.6671,
      "step": 25
    },
    {
      "epoch": 0.009317326643970614,
      "grad_norm": 1.0532517433166504,
      "learning_rate": 4.985666507405638e-05,
      "loss": 0.5446,
      "step": 26
    },
    {
      "epoch": 0.009675685361046408,
      "grad_norm": 0.8239157795906067,
      "learning_rate": 4.9850692785475395e-05,
      "loss": 0.6769,
      "step": 27
    },
    {
      "epoch": 0.0100340440781222,
      "grad_norm": 0.5259680151939392,
      "learning_rate": 4.984472049689442e-05,
      "loss": 0.5561,
      "step": 28
    },
    {
      "epoch": 0.010392402795197993,
      "grad_norm": 0.37262845039367676,
      "learning_rate": 4.983874820831343e-05,
      "loss": 0.5671,
      "step": 29
    },
    {
      "epoch": 0.010750761512273785,
      "grad_norm": 0.3263879716396332,
      "learning_rate": 4.983277591973244e-05,
      "loss": 0.532,
      "step": 30
    },
    {
      "epoch": 0.01110912022934958,
      "grad_norm": 0.3708037734031677,
      "learning_rate": 4.982680363115146e-05,
      "loss": 0.6144,
      "step": 31
    },
    {
      "epoch": 0.011467478946425372,
      "grad_norm": 0.3715900182723999,
      "learning_rate": 4.9820831342570475e-05,
      "loss": 0.8116,
      "step": 32
    },
    {
      "epoch": 0.011825837663501164,
      "grad_norm": 0.2281980961561203,
      "learning_rate": 4.981485905398949e-05,
      "loss": 0.536,
      "step": 33
    },
    {
      "epoch": 0.012184196380576957,
      "grad_norm": 0.20869657397270203,
      "learning_rate": 4.980888676540851e-05,
      "loss": 0.5718,
      "step": 34
    },
    {
      "epoch": 0.01254255509765275,
      "grad_norm": 0.26453036069869995,
      "learning_rate": 4.980291447682752e-05,
      "loss": 0.5782,
      "step": 35
    },
    {
      "epoch": 0.012900913814728543,
      "grad_norm": 0.20718535780906677,
      "learning_rate": 4.979694218824654e-05,
      "loss": 0.5933,
      "step": 36
    },
    {
      "epoch": 0.013259272531804336,
      "grad_norm": 0.2096778005361557,
      "learning_rate": 4.979096989966555e-05,
      "loss": 0.5738,
      "step": 37
    },
    {
      "epoch": 0.013617631248880128,
      "grad_norm": 0.1907060295343399,
      "learning_rate": 4.978499761108457e-05,
      "loss": 0.5671,
      "step": 38
    },
    {
      "epoch": 0.013975989965955922,
      "grad_norm": 0.42075276374816895,
      "learning_rate": 4.977902532250359e-05,
      "loss": 0.5518,
      "step": 39
    },
    {
      "epoch": 0.014334348683031715,
      "grad_norm": 0.1869766116142273,
      "learning_rate": 4.97730530339226e-05,
      "loss": 0.6313,
      "step": 40
    },
    {
      "epoch": 0.014692707400107507,
      "grad_norm": 0.2915135324001312,
      "learning_rate": 4.976708074534161e-05,
      "loss": 0.5431,
      "step": 41
    },
    {
      "epoch": 0.0150510661171833,
      "grad_norm": 0.21010395884513855,
      "learning_rate": 4.9761108456760635e-05,
      "loss": 0.5521,
      "step": 42
    },
    {
      "epoch": 0.015409424834259094,
      "grad_norm": 0.17786701023578644,
      "learning_rate": 4.975513616817965e-05,
      "loss": 0.5294,
      "step": 43
    },
    {
      "epoch": 0.015767783551334884,
      "grad_norm": 0.19910797476768494,
      "learning_rate": 4.974916387959867e-05,
      "loss": 0.5891,
      "step": 44
    },
    {
      "epoch": 0.01612614226841068,
      "grad_norm": 0.20209500193595886,
      "learning_rate": 4.9743191591017676e-05,
      "loss": 0.5571,
      "step": 45
    },
    {
      "epoch": 0.016484500985486473,
      "grad_norm": 0.18157163262367249,
      "learning_rate": 4.973721930243669e-05,
      "loss": 0.5636,
      "step": 46
    },
    {
      "epoch": 0.016842859702562264,
      "grad_norm": 0.20442518591880798,
      "learning_rate": 4.9731247013855715e-05,
      "loss": 0.6321,
      "step": 47
    },
    {
      "epoch": 0.017201218419638058,
      "grad_norm": 0.1713770627975464,
      "learning_rate": 4.972527472527473e-05,
      "loss": 0.5126,
      "step": 48
    },
    {
      "epoch": 0.017559577136713852,
      "grad_norm": 0.17678509652614594,
      "learning_rate": 4.971930243669374e-05,
      "loss": 0.5431,
      "step": 49
    },
    {
      "epoch": 0.017917935853789643,
      "grad_norm": 0.17626811563968658,
      "learning_rate": 4.9713330148112756e-05,
      "loss": 0.4775,
      "step": 50
    },
    {
      "epoch": 0.018276294570865437,
      "grad_norm": 0.1643982082605362,
      "learning_rate": 4.970735785953177e-05,
      "loss": 0.5168,
      "step": 51
    },
    {
      "epoch": 0.018634653287941227,
      "grad_norm": 0.16538436710834503,
      "learning_rate": 4.9701385570950795e-05,
      "loss": 0.4727,
      "step": 52
    },
    {
      "epoch": 0.01899301200501702,
      "grad_norm": 0.17588351666927338,
      "learning_rate": 4.9695413282369804e-05,
      "loss": 0.5673,
      "step": 53
    },
    {
      "epoch": 0.019351370722092816,
      "grad_norm": 0.1993636041879654,
      "learning_rate": 4.968944099378882e-05,
      "loss": 0.7076,
      "step": 54
    },
    {
      "epoch": 0.019709729439168606,
      "grad_norm": 0.19924584031105042,
      "learning_rate": 4.9683468705207836e-05,
      "loss": 0.5164,
      "step": 55
    },
    {
      "epoch": 0.0200680881562444,
      "grad_norm": 0.17927846312522888,
      "learning_rate": 4.967749641662686e-05,
      "loss": 0.5028,
      "step": 56
    },
    {
      "epoch": 0.020426446873320195,
      "grad_norm": 0.18965227901935577,
      "learning_rate": 4.967152412804587e-05,
      "loss": 0.515,
      "step": 57
    },
    {
      "epoch": 0.020784805590395986,
      "grad_norm": 0.16628322005271912,
      "learning_rate": 4.9665551839464884e-05,
      "loss": 0.4669,
      "step": 58
    },
    {
      "epoch": 0.02114316430747178,
      "grad_norm": 0.1917169988155365,
      "learning_rate": 4.96595795508839e-05,
      "loss": 0.5215,
      "step": 59
    },
    {
      "epoch": 0.02150152302454757,
      "grad_norm": 0.17563919723033905,
      "learning_rate": 4.9653607262302916e-05,
      "loss": 0.5229,
      "step": 60
    },
    {
      "epoch": 0.021859881741623365,
      "grad_norm": 0.19013163447380066,
      "learning_rate": 4.964763497372193e-05,
      "loss": 0.5886,
      "step": 61
    },
    {
      "epoch": 0.02221824045869916,
      "grad_norm": 0.17237918078899384,
      "learning_rate": 4.964166268514095e-05,
      "loss": 0.5383,
      "step": 62
    },
    {
      "epoch": 0.02257659917577495,
      "grad_norm": 0.16468462347984314,
      "learning_rate": 4.9635690396559964e-05,
      "loss": 0.4271,
      "step": 63
    },
    {
      "epoch": 0.022934957892850744,
      "grad_norm": 0.1634742170572281,
      "learning_rate": 4.962971810797898e-05,
      "loss": 0.3951,
      "step": 64
    },
    {
      "epoch": 0.023293316609926538,
      "grad_norm": 0.18364879488945007,
      "learning_rate": 4.9623745819397996e-05,
      "loss": 0.495,
      "step": 65
    },
    {
      "epoch": 0.02365167532700233,
      "grad_norm": 0.19067758321762085,
      "learning_rate": 4.961777353081701e-05,
      "loss": 0.5052,
      "step": 66
    },
    {
      "epoch": 0.024010034044078123,
      "grad_norm": 0.17453205585479736,
      "learning_rate": 4.961180124223603e-05,
      "loss": 0.4463,
      "step": 67
    },
    {
      "epoch": 0.024368392761153913,
      "grad_norm": 0.18469516932964325,
      "learning_rate": 4.9605828953655044e-05,
      "loss": 0.489,
      "step": 68
    },
    {
      "epoch": 0.024726751478229708,
      "grad_norm": 0.18034368753433228,
      "learning_rate": 4.959985666507406e-05,
      "loss": 0.5132,
      "step": 69
    },
    {
      "epoch": 0.0250851101953055,
      "grad_norm": 0.20600056648254395,
      "learning_rate": 4.9593884376493076e-05,
      "loss": 0.5373,
      "step": 70
    },
    {
      "epoch": 0.025443468912381292,
      "grad_norm": 0.1936316043138504,
      "learning_rate": 4.958791208791209e-05,
      "loss": 0.5291,
      "step": 71
    },
    {
      "epoch": 0.025801827629457087,
      "grad_norm": 0.1939651519060135,
      "learning_rate": 4.958193979933111e-05,
      "loss": 0.4826,
      "step": 72
    },
    {
      "epoch": 0.02616018634653288,
      "grad_norm": 0.18426266312599182,
      "learning_rate": 4.9575967510750124e-05,
      "loss": 0.4285,
      "step": 73
    },
    {
      "epoch": 0.02651854506360867,
      "grad_norm": 0.1788136512041092,
      "learning_rate": 4.9569995222169133e-05,
      "loss": 0.3925,
      "step": 74
    },
    {
      "epoch": 0.026876903780684466,
      "grad_norm": 0.31094104051589966,
      "learning_rate": 4.9564022933588156e-05,
      "loss": 0.4312,
      "step": 75
    },
    {
      "epoch": 0.027235262497760256,
      "grad_norm": 0.2370317578315735,
      "learning_rate": 4.955805064500717e-05,
      "loss": 0.5078,
      "step": 76
    },
    {
      "epoch": 0.02759362121483605,
      "grad_norm": 0.21878604590892792,
      "learning_rate": 4.955207835642619e-05,
      "loss": 0.4294,
      "step": 77
    },
    {
      "epoch": 0.027951979931911845,
      "grad_norm": 0.19398300349712372,
      "learning_rate": 4.95461060678452e-05,
      "loss": 0.3609,
      "step": 78
    },
    {
      "epoch": 0.028310338648987635,
      "grad_norm": 0.19758161902427673,
      "learning_rate": 4.954013377926421e-05,
      "loss": 0.397,
      "step": 79
    },
    {
      "epoch": 0.02866869736606343,
      "grad_norm": 0.21422527730464935,
      "learning_rate": 4.9534161490683236e-05,
      "loss": 0.4557,
      "step": 80
    }
  ],
  "logging_steps": 1,
  "max_steps": 8373,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 10,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2773196294062080.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
